# Neural Networks From Scratch

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python 3.12](https://img.shields.io/badge/python-3.12+-blue.svg)](https://www.python.org/downloads/)
[![Jupyter Notebook](https://img.shields.io/badge/Jupyter-Notebook-orange.svg)](https://jupyter.org/)
[![NumPy](https://img.shields.io/badge/NumPy-1.26.4-blue.svg)](https://numpy.org)
[![Matplotlib](https://img.shields.io/badge/Matplotlib-3.8.0-blue.svg)](https://matplotlib.org)
[![Manim](https://img.shields.io/badge/Manim-Animation%20Library-green.svg)](https://github.com/3b1b/manim)

A step-by-step implementation guide to understanding neural networks, starting from a single neuron to complex multi-layer architectures. Perfect for learning fundamental concepts through code!

## ğŸ“– Table of Contents
- [Project Overview](#-project-overview)
- [Notebook Structure](#-notebook-structure)
- [Features](#-features)
- [Installation](#-installation)
- [Usage](#-usage)
- [Contributing](#-contributing)
- [License](#-license)
- [Contact](#-contact)

## ğŸŒŸ Project Overview
This project is an educational journey through neural network fundamentals, implemented in Python with NumPy. Each notebook progressively builds complexity:

- **NN1**: Single neuron implementation with theoretical knowledge
- **NN2**: Multiple neurons and hidden layers
- **NN3**: Deep neural networks with advanced techniques

All implementations are accompanied by detailed mathematical explanations and visualizations.

## ğŸ“š Notebook Structure

### `NN1 - Single Neuron Implementation` (Work in progress)
- Biological inspiration for artificial neurons
- Activation functions (Sigmoid, ReLU)
- Forward propagation
- Loss calculation (MSE, Cross-Entropy)
- Backpropagation basics
- Training loop implementation

### `NN2 - Multi-Layer Perceptron` (Not yet added)
- Layer-wise architecture
- Matrix operations for efficient computation
- Hidden layers and depth concepts
- Vanishing gradient problem
- Weight initialization techniques

### `NN3 - Deep Neural Networks` (Not yet added)
- Batch normalization
- Dropout regularization
- Advanced optimizers (Adam, RMSProp)
- Hyperparameter tuning
- Classification on standard datasets

## âœ¨ Features
- ğŸ§  From first principles to practical implementations
- ğŸ“ˆ Visualizations of learning processes
- ğŸ” Mathematical derivations with LaTeX explanations
- âš™ï¸ Pure NumPy implementations (no high-level frameworks)
- ğŸ’¡ Interactive code cells for experimentation

## ğŸ™Œ Special Thanks
The mathematical animations in these notebooks are created using the incredible [Manim](https://github.com/3b1b/manim) animation library developed by [3Blue1Brown](https://www.3blue1brown.com/).

## ğŸ› ï¸ Installation
1. Clone repository:
   ```bash
   git clone https://github.com/laasriy/Data-Science/Neural Network

2. Enjoy ğŸ“š !!


